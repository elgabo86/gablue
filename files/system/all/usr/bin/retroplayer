#!/bin/bash

# Vérifier que zxtune-qt est installé
if ! command -v zxtune-qt &> /dev/null; then
    echo "zxtune-qt n'est pas installé. Veuillez l'installer pour utiliser ce script."
    exit 1
fi

# Vérifier que fzf est installé
if ! command -v fzf &> /dev/null; then
    echo "fzf n'est pas installé. Veuillez l'installer pour utiliser ce script."
    echo "Sur Debian/Ubuntu: sudo apt install fzf"
    echo "Sur Arch: sudo pacman -S fzf"
    echo "Sur macOS: brew install fzf"
    exit 1
fi

# Vérifier que curl est installé
if ! command -v curl &> /dev/null; then
    echo "curl n'est pas installé. Veuillez l'installer pour utiliser ce script."
    exit 1
fi

# Vérifier que sqlite3 est installé
if ! command -v sqlite3 &> /dev/null; then
    echo "sqlite3 n'est pas installé. Veuillez l'installer pour utiliser ce script."
    echo "Sur Debian/Ubuntu: sudo apt install sqlite3"
    echo "Sur Arch: sudo pacman -S sqlite"
    echo "Sur macOS: brew install sqlite"
    exit 1
fi

# Vérifier que 7z est installé
if ! command -v 7z &> /dev/null; then
    echo "7z n'est pas installé. Veuillez l'installer pour utiliser ce script."
    echo "Sur Debian/Ubuntu: sudo apt install p7zip-full"
    echo "Sur Arch: sudo pacman -S p7zip"
    echo "Sur macOS: brew install p7zip"
    exit 1
fi

# Variables globales
TEMP_DIR="${HOME}/.cache/retroplayer"
mkdir -p "$TEMP_DIR"

DB_FILE="$TEMP_DIR/retroplayer.db"

# Fonction de nettoyage pour supprimer les fichiers temporaires laissés par des exécutions précédentes
cleanup_previous_sessions() {
    # Supprimer silencieusement les fichiers .7z dans le dossier temporaire
    find "$TEMP_DIR" -maxdepth 1 -name "*.7z" -type f -delete 2>/dev/null
}

# Exécuter le nettoyage au démarrage
cleanup_previous_sessions

BASE_SITES=(
    "https://spc.joshw.info"
    "https://nsf.joshw.info"
    "https://usf.joshw.info"
    "https://smd.joshw.info"
    "https://psf.joshw.info"
    "https://psf2.joshw.info"
    "https://gbs.joshw.info"
    "https://gsf.joshw.info"
    "https://2sf.joshw.info"
)

# Fonction de nettoyage pour supprimer les fichiers temporaires
cleanup() {
    echo -e "\nNettoyage des fichiers temporaires..."
    # Supprimer tous les fichiers .7z dans le dossier temporaire
    rm -f "$TEMP_DIR"/*.7z 2>/dev/null

    # Fermer proprement la base de données
    sqlite3 "$DB_FILE" "PRAGMA wal_checkpoint(TRUNCATE);" 2>/dev/null

    echo "Fichiers temporaires supprimés."
    exit 0
}

# Enregistrer la fonction de nettoyage pour s'exécuter lors d'une interruption
trap cleanup SIGINT SIGTERM

# Initialiser la base de données SQLite
init_db() {
    sqlite3 "$DB_FILE" <<EOF >/dev/null 2>&1
PRAGMA journal_mode = WAL;
PRAGMA synchronous = NORMAL;
PRAGMA cache_size = 10000;
PRAGMA temp_store = MEMORY;
PRAGMA mmap_size = 268435456;

CREATE TABLE IF NOT EXISTS files (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    site TEXT NOT NULL,
    folder TEXT NOT NULL,
    file_name TEXT NOT NULL,
    file_path TEXT NOT NULL,
    UNIQUE(site, folder, file_name)
);

CREATE INDEX IF NOT EXISTS idx_files_site ON files(site);
CREATE INDEX IF NOT EXISTS idx_files_folder ON files(folder);
CREATE INDEX IF NOT EXISTS idx_files_name ON files(file_name);
CREATE INDEX IF NOT EXISTS idx_files_composite ON files(site, folder, file_name);
EOF
}

# Fonction pour scraper un dossier et mettre à jour la base de données
scrape_folder() {
    local site="$1"
    local folder="$2"

    # Récupérer le contenu du dossier
    local html=$(curl -s --max-time 5 "$site/$folder/" 2>/dev/null)

    if [ -z "$html" ]; then
        return
    fi

    # Début de la transaction
    echo "BEGIN TRANSACTION;" > /tmp/retroplayer_inserts.sql

    # Extraire tous les liens .7z (tous les sites utilisent .7z)
    echo "$html" | grep -oE "href=\"[^\"]*\.7z\">[^<]*" 2>/dev/null | while read -r line; do
        # Extraire le fichier et le nom
        local file=$(echo "$line" | sed -E 's/href="([^"]*)">.*/\1/')
        local file_name=$(echo "$line" | sed -E 's/href="[^"]*">(.*)/\1/')

        # Échapper les apostrophes pour SQLite
        local escaped_file_name=$(echo "$file_name" | sed "s/'/''/g")
        local escaped_file_path=$(echo "$file" | sed "s/'/''/g")

        # Ajouter l'instruction d'insertion au fichier SQL
        echo "INSERT OR IGNORE INTO files (site, folder, file_name, file_path) VALUES ('$site', '$folder', '$escaped_file_name', '$escaped_file_path');" >> /tmp/retroplayer_inserts.sql
    done

    # Fin de la transaction
    echo "COMMIT;" >> /tmp/retroplayer_inserts.sql

    # Exécuter toutes les insertions en une seule transaction
    sqlite3 "$DB_FILE" < /tmp/retroplayer_inserts.sql 2>/dev/null

    # Nettoyer le fichier temporaire
    rm -f /tmp/retroplayer_inserts.sql
}

# Fonction pour scraper tous les dossiers d'un site
scrape_site() {
    local site="$1"

    # Créer une liste de tous les dossiers
    local folders=("0-9")
    for letter in {a..z}; do
        folders+=("$letter")
    done
    folders+=(zzz_prototypes zzz_unlicensed)

    # Parcourir tous les dossiers avec parallélisation (max 5 processus simultanés)
    local total=${#folders[@]}
    local batch_size=5

    # Créer un fichier temporaire pour stocker toutes les insertions
    local temp_sql_file="/tmp/retroplayer_site_inserts_$.sql"
    echo "BEGIN TRANSACTION;" > "$temp_sql_file"

    # Traitement par lots
    for ((i=0; i<total; i+=batch_size)); do
        # Créer un tableau pour les PIDs des processus
        local pids=()

        # Lancer un lot de processus
        for ((j=0; j<batch_size && i+j<total; j++)); do
            local folder_index=$((i+j))
            local folder="${folders[$folder_index]}"

            # Lancer le scraping du dossier en arrière-plan
            (
                # Récupérer le contenu du dossier
                local html=$(curl -s --max-time 5 "$site/$folder/" 2>/dev/null)

                if [ -n "$html" ]; then
                    # Extraire tous les liens .7z et générer les insertions SQL
                    echo "$html" | grep -oE "href=\"[^\"]*\.7z\">[^<]*" 2>/dev/null | while read -r line; do
                        # Extraire le fichier et le nom
                        local file=$(echo "$line" | sed -E 's/href="([^"]*)">.*/\1/')
                        local file_name=$(echo "$line" | sed -E 's/href="[^"]*">(.*)/\1/')

                        # Échapper les apostrophes pour SQLite
                        local escaped_file_name=$(echo "$file_name" | sed "s/'/''/g")
                        local escaped_file_path=$(echo "$file" | sed "s/'/''/g")

                        # Afficher l'instruction d'insertion
                        echo "INSERT OR IGNORE INTO files (site, folder, file_name, file_path) VALUES ('$site', '$folder', '$escaped_file_name', '$escaped_file_path');"
                    done
                fi
            ) >> "$temp_sql_file" &

            # Stocker le PID du processus
            pids+=($!)
        done

        # Attendre que tous les processus du lot se terminent
        for pid in "${pids[@]}"; do
            wait "$pid"
        done
    done

    # Terminer la transaction
    echo "COMMIT;" >> "$temp_sql_file"

    # Exécuter toutes les insertions en une seule transaction
    sqlite3 "$DB_FILE" < "$temp_sql_file" 2>/dev/null

    # Nettoyer le fichier temporaire
    rm -f "$temp_sql_file"
}

# Fonction pour mettre à jour le cache
update_cache() {
    echo "Mise à jour du cache en cours..."
    echo "Cela peut prendre quelques minutes lors de la première exécution."
    echo ""

    # Paralléliser le scraping des sites (max 3 sites simultanément)
    local batch_size=3
    local total_sites=${#BASE_SITES[@]}
    local processed_sites=0

    # Afficher la première ligne de progression
    echo -ne "Sites traités: $processed_sites/$total_sites\r"

    # Traitement par lots de sites
    for ((i=0; i<total_sites; i+=batch_size)); do
        # Créer un tableau pour les PIDs des processus
        local pids=()

        # Lancer un lot de processus pour les sites
        for ((j=0; j<batch_size && i+j<total_sites; j++)); do
            local site_index=$((i+j))
            local site="${BASE_SITES[$site_index]}"

            # Lancer le scraping du site en arrière-plan
            (
                scrape_site "$site"
            ) &

            # Stocker le PID du processus
            pids+=($!)
        done

        # Attendre que tous les processus du lot se terminent
        for pid in "${pids[@]}"; do
            wait "$pid"
            processed_sites=$((processed_sites + 1))
            # Mettre à jour la ligne de progression
            echo -ne "Sites traités: $processed_sites/$total_sites\r"
        done
    done

    # Afficher la ligne terminée
    echo -e "\nMise à jour du cache terminée."
    echo ""
}

# Fonction pour rechercher et jouer un fichier
search_and_play() {
    local search_term="$1"

    # Vérifier si la base de données existe et contient des données
    local count=$(sqlite3 "$DB_FILE" "SELECT COUNT(*) FROM files;" 2>/dev/null)
    if [ -z "$count" ] || [ "$count" -eq 0 ]; then
        echo "Base de données vide. Mise à jour du cache requise."
        update_cache
    fi

    # Récupérer les fichiers
    mapfile -t RESULTS < <(fetch_files "$search_term")

    if [ ${#RESULTS[@]} -eq 0 ]; then
        echo "Aucun fichier trouvé."
        return 1
    fi

    # Utiliser fzf pour sélectionner un fichier
    # Extraire uniquement les noms de fichiers pour fzf
    FILE_NAMES=()
    for line in "${RESULTS[@]}"; do
        file_name=$(echo "$line" | cut -d$'\t' -f2)
        # Décoder les entités HTML dans le nom du fichier
        file_name=$(decode_html_entities "$file_name")
        FILE_NAMES+=("$file_name")
    done

    # Utiliser fzf pour la sélection
    selected_name=$(printf '%s\n' "${FILE_NAMES[@]}" | fzf --prompt="Sélectionnez un fichier > " --height=40%)

    # Vérifier si l'utilisateur a annulé la sélection
    if [ -z "$selected_name" ]; then
        echo "Aucun fichier sélectionné."
        return 1
    fi

    # Trouver l'entrée correspondante
    for line in "${RESULTS[@]}"; do
        file_name=$(echo "$line" | cut -d$'\t' -f2)
        # Décoder les entités HTML pour la comparaison
        file_name_decoded=$(decode_html_entities "$file_name")
        if [ "$file_name_decoded" = "$selected_name" ]; then
            selected_line="$line"
            break
        fi
    done

    # Vérifier si selected_line a été trouvé
    if [ -z "$selected_line" ]; then
        echo "Erreur: Impossible de trouver le fichier sélectionné dans les résultats."
        return 1
    fi

    # Extraire les informations du fichier sélectionné
    # Extraire les champs en utilisant la tabulation comme délimiteur
    site=$(echo "$selected_line" | cut -d$'\t' -f1)
    file_name=$(echo "$selected_line" | cut -d$'\t' -f2)
    file_path=$(echo "$selected_line" | cut -d$'\t' -f3)

    # Vérifier si les variables sont vides
    if [ -z "$site" ] || [ -z "$file_name" ] || [ -z "$file_path" ]; then
        echo "Erreur: Impossible d'extraire les informations du fichier."
        return 1
    fi

    # Construire l'URL complète correctement
    # S'assurer qu'il y a un / entre le site et le chemin du fichier
    # Les chemins dans la base de données sont déjà encodés
    # Pour SPC, NSF, SMD, GBS, PSF, PSF2, 2SF, USF, GSF : utiliser la première lettre du fichier comme répertoire
    if [[ "$site" == *".joshw.info"* ]]; then
        # Décoder les entités HTML dans le chemin du fichier
        # Remplacer &amp; par & dans le chemin
        fixed_file_path=$(echo "$file_path" | sed 's/&amp;/\&/g')

        # Extraire la première lettre du fichier
        # Décoder l'URL pour obtenir le nom réel du fichier
        decoded_file_path=$(printf '%b' "${fixed_file_path//%/\\x}")
        first_letter=$(echo "$decoded_file_path" | cut -c1 | tr '[:upper:]' '[:lower:]')
        # Si c'est un chiffre, utiliser 0-9
        if [[ "$first_letter" =~ [0-9] ]]; then
            first_letter="0-9"
        fi
        # Utiliser le chemin corrigé
        file_url="$site/$first_letter/$fixed_file_path"
    else
        # Pour tous les autres sites, utiliser le chemin direct
        file_url="$site/$file_path"
    fi

    # Créer le chemin du fichier temporaire avec le nom décrypté
    # Extraire le nom de fichier de file_path (tout ce qui suit le dernier /)
    # Décoder l'URL pour obtenir le nom de fichier réel
    encoded_file_name=$(basename "$file_path")
    decoded_file_name=$(printf '%b' "${encoded_file_name//%/\\x}")

    # S'assurer que decoded_file_name n'est pas vide
    if [ -z "$decoded_file_name" ]; then
        echo "Erreur: Impossible de décoder le nom du fichier."
        return 1
    fi

    # Remplacer les apostrophes par des espaces dans le nom du fichier pour éviter les problèmes
    decoded_file_name=$(echo "$decoded_file_name" | sed "s/'/ /g")

    temp_file="$TEMP_DIR/$decoded_file_name"

    # Vérifier si le nom de fichier se termine par .7z, sinon l'ajouter
    if [[ "$temp_file" != *.7z ]]; then
        temp_file="${temp_file}.7z"
    fi

    # Supprimer les playlists existantes dans ZXTune
    playlists_dir="$HOME/.local/share/ZXTune/Playlists"
    if [ -d "$playlists_dir" ]; then
        rm -f "$playlists_dir"/*.xspf 2>/dev/null
    fi

    # Télécharger le fichier
    echo "Téléchargement en cours..."

    if curl -s -L "$file_url" -o "$temp_file"; then
        # Vérifier si le fichier est une archive 7z valide
        if 7z t "$temp_file" >/dev/null 2>&1; then
            echo "Lancement de zxtune-qt..."

            # Jouer avec zxtune-qt (il gère les archives .7z automatiquement)
            # Cacher les sorties de zxtune
            zxtune-qt "$temp_file" >/dev/null 2>&1

            # Supprimer le fichier après fermeture
            if rm "$temp_file"; then
                echo "Fichier temporaire supprimé."
            else
                echo "Erreur lors de la suppression du fichier."
            fi
        else
            echo "Erreur: L'archive téléchargée n'est pas valide ou corrompue."
            echo "URL problématique: $file_url"
            echo "Fichier temporaire: $temp_file"
            # Supprimer le fichier corrompu
            rm "$temp_file" 2>/dev/null
        fi
    else
        echo "Échec du téléchargement."
        echo "URL problématique: $file_url"
        return 1
    fi

    return 0
}

# Fonction pour récupérer les fichiers
fetch_files() {
    local search_term="$1"

    # Convertir le terme de recherche en minuscules pour la comparaison
    local search_term_lower=$(echo "$search_term" | tr '[:upper:]' '[:lower:]')

    # Diviser le terme de recherche en mots
    read -ra SEARCH_WORDS <<< "$search_term_lower"

    # Construire la requête SQL avec plusieurs conditions LIKE
    local sql_query="SELECT site, file_name, file_path FROM files WHERE "
    local first_word=1

    for word in "${SEARCH_WORDS[@]}"; do
        if [ $first_word -eq 1 ]; then
            sql_query+="LOWER(file_name) LIKE '%$word%'"
            first_word=0
        else
            sql_query+=" AND LOWER(file_name) LIKE '%$word%'"
        fi
    done

    # Exécuter la requête SQL
    sqlite3 "$DB_FILE" ".mode tabs" "$sql_query;"
}

# Fonction pour décoder les entités HTML dans les noms de fichiers
decode_html_entities() {
    local input="$1"
    echo "$input" | sed 's/&amp;/\&/g'
}

# Initialiser la base de données
init_db

# Vérifier si la base de données existe et contient des données
# Si elle est vide, mettre à jour le cache automatiquement
count=$(sqlite3 "$DB_FILE" "SELECT COUNT(*) FROM files;" 2>/dev/null)
if [ -z "$count" ] || [ "$count" -eq 0 ]; then
    echo "Base de données vide. Mise à jour du cache automatique..."
    update_cache
fi

# Si aucun argument n'est fourni, demander interactivement le terme de recherche
if [ $# -eq 0 ]; then
    echo "Recherche interactive de fichiers musicaux"
    echo ""

    # Boucle interactive
    while true; do
        # Demander le terme de recherche
        read -p "Entrez les mots clés de recherche: " SEARCH_TERM

        # Si l'utilisateur n'a rien entré, quitter
        if [ -z "$SEARCH_TERM" ]; then
            echo "Aucun terme de recherche fourni. Au revoir!"
            exit 0
        fi

        # Si l'utilisateur tape "update", mettre à jour le cache
        if [ "$SEARCH_TERM" = "update" ]; then
            update_cache
            continue
        fi

        # Exécuter la recherche
        search_and_play "$SEARCH_TERM"
        result=$?

        # Si la recherche a retourné 2, c'est qu'on veut une nouvelle recherche
        if [ $result -eq 2 ]; then
            echo ""
            echo "Nouvelle recherche..."
            echo ""
            continue
        fi

        echo ""
        echo "Recherche terminée."
        echo ""
    done
else
    # Mode avec argument
    SEARCH_TERM="$1"
    echo "Recherche de fichiers contenant '$SEARCH_TERM'..."
    search_and_play "$SEARCH_TERM"
fi
